
# 15M Lost Annually To Poor Data Quality

Many organizations today are plagued by poor **[data quality management](https://hackernoon.com/database-vs-data-warehouse-vs-data-lake-a-simple-explanation-hz2k33rm)**. This, in turn, is followed by huge burns in pockets. According to Gartner, poor data quality is knocking companies to the ground – to the tune of $15 million as the average annual financial cost. Wasted resources and expenditures for operational inefficiencies, missed sales and untaken chances come complete with poor quality data.

We get it, **[it's a tough call](https://hackernoon.com/visualizing-the-data-spotify-data-for-favorite-artists-over-time-3p9r35h1)**. So if you're still struggling with bad data, we're here to shed light on data quality and top practices to make your data sets serve **[the goals](https://hackernoon.com/the-benefits-of-idea-validation-and-how-to-conduct-it-part-1-h58m331l)**. Let's reliably deliver insight into your company.





![alt_text](images/image1.gif "image_tooltip")
https://giphy.com/gifs/cute-space-astronaut-xT8qBhrlNooHBYR9f2


## Establish meaningful metrics

By setting up a program of data quality metrics and measuring religiously companies **[can raise awareness](https://hackernoon.com/8-skills-required-to-become-a-data-scientist-qt24331s)** of how critical data quality is for the organization. As for the exact metrics, your mileage can vary. The golden rule here is to make them applicable to the goals and **[business targets](https://hackernoon.com/get-started-with-big-data-analytics-for-your-business-804i35b7)** you are aiming for with your data. Thus, your metrics can target the accuracy, completeness, or validity of your data. You can also assess the number of redundant entries or **[format-incompatible data](https://hackernoon.com/artificial-intelligence-multimillennial-data-transmitted-to-machines-with-brains-x410337v)**.





![alt_text](images/image2.gif "image_tooltip")
https://giphy.com/gifs/salesforce-confetti-success-customer-zoKdmndB8QBR2c0gjy


## Trust but validate

Data does not have a long shelf-life. Therefore, all data needs to be validated, i.e. checked for accuracy, clarity, and details. When moving and merging data it’s vital to check the conformity of diverse data sets to **[business rules](https://hackernoon.com/what-is-big-data-understanding-the-business-use-of-big-data-analytics-l2ar35xq)**. Otherwise, you risk basing decisions on imperfect and inconsistent data. **[Example validation checks](https://hackernoon.com/how-to-keep-your-machine-learning-models-up-to-date-vd5z3yzw)** may include:
*   Ensuring that age is entered as a whole number
*   Ensuring that the email address includes the @ symbol
*   Ensuring that usernames include only letters and numbers, etc.





![alt_text](images/image3.gif "image_tooltip")
https://giphy.com/gifs/itvstudiosfrance-the-voice-thevoice-france-JGW08QZkv1u45o4W1W

This requires having the right **[tools](https://hackernoon.com/tagged/tools)** _and_ the right processes. On this note, **Soda.io** makes it **easy to test and validate your data** against the business rules that are vital to your company.


## Implement a single source of truth

In its essence, a single source of truth refers to **[the data](https://hackernoon.com/tagged/data)** practice when all business-critical data is stored in one place. An SSOT ensures that all team players base their decisions on the same data via a single reference point. Instead of being a specific software, it’s more of a state of mind for your company. An SSOT can be anything from a simple doc to a sophisticated data information architecture your organization leverages. 





![alt_text](images/image4.gif "image_tooltip")
https://giphy.com/gifs/theoffice-the-office-tv-golden-ticket-dXFKDUolyLLi8gq6Cl


_A pro tip (or two)_: In today’s **[remote-first environment](https://hackernoon.com/sql-and-database-management-skills-should-be-introduced-into-school-curriculums-nu9k35sy)**, it’s important to check that an SSOT is accessible to all team players. Also, grant independent access to the team if you’re collaborating with folks in another time zone.


## The End

Getting in front of **[data quality](https://hackernoon.com/interpreting-big-data-data-science-vs-data-analytics-wpdi358j)** is both terrifying and exciting. Probably, that is the main reason why most companies don’t give data quality its due. But bad data is not a norm. If you are looking **[to reduce the number of mistakes](https://hackernoon.com/identifying-handwritten-digits-from-the-mnist-dataset-using-python-0c2k335e)**, budget dollars, and unwise business decisions, you should definitely go the extra mile with your data sets. 
